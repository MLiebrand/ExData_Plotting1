good <- gss[order(gss$confed), na.rm=TRUE]
good <- gss[order(gss$confed)]
good <- gss$confed
good
?Dbinorm
?dbinom
dbinom(1000, 28.2)
sum(dbinom(50:160, size=160, p =0.28))
sum(dbinom(50:160, size=160, p =0.28, upper.tail=TRUE))
sum(dbinom(50:160, size=160, p =0.28, upper.tail=TRUE))
sum(dbinom(50:160, size=160, p =0.28, lower.tail=FALSE))
sum(dbinom(50:160, size=160, p =0.28))
?pnorm
pnorm(1800, 1500, 300)
?dbinorm
dbinom
?dbinom
?inference
?by
pf(5.2, 4, 50735, lower.tail = FALSE)
?unique
sum(dbinom(35:250, 250, 0.10))
library(DAAG)
install.package("DAAG")
instal.packages("DAAG")
install.packages("DAAG")
library("DAAG", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
library(DAAG)
data(allbacks)
book_mlr = lm(weight ~volume + cover, data = allbacks)
summary(book_mlr)
states = read.csv("http://bit.ly/dasi_states")
pov_slr = lm(poverty ~ female_house, data = states)
summary(pov_slr)
?boxplot
install.packages("KernSmooth")
load(KernSmooth)
library("KernSmooth", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
dbinom(1,5, .2)
dbinom(2, 10, .1)
dbinom(2, 10, .2)
dbinom(3, 15, .1)
dbinom(3, 15, .2)
cognitive = read.csv("http://bit.ly/dasi_cognitive")
cog_full = lm(kid_score ~mom_hs + mom_iq + mom_work + mom_age, data = cognitive)
summary(cog_full)
sum(dbinom(18:100, 100, .11))
pf(3.4, 2, 828)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
data <-read.table(fileUrl)
download.file(fileUrl, destfile = "quiz1.csv", method="curl")
quize.csv
quiz.csv
list.files()
loadQuiz1 <-read.table("quiz1.csv")
loadQuiz1
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
data <-read.table(fileUrl)
data <-read.table(fileUrl)
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
data <-read.table(fileUrl)
download.file(fileUrl, destfile = "quiz1.csv", method="curl")
fileCodeBook <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FPUMSDataDict06.pdf"
download.file(fileCodeBook, destfile = "codebook.pdf", method="curl")
getwd()
data(data$VAL > 1000000)
View(data)
View(data)
data(V1$VAL > 1000000)
View(data)
View(data)
data
data(data$VAL > 1000000)
data(data$VAL > "1000000")
data[data$VAL > 1000000]
data[data$VAL == 24]
data[data$VAL == 18]
data[data$VAL == "18]
""
end''
l
=
quit
end
""
data[data$VAL == "18"]
data[data$VAL]
data[V1$VAL]
head(data)
tables()
library(data.table)
class(data)
loadQuiz1 <-read.table("quiz1.csv", header=FALSE, stringsAsFactors = FALSE)
data <-read.table(fileUrl,  header=FALSE, stringsAsFactors = FALSE)
View(data)
View(data)
data[data$VAL]
data[,data$VAL]
data <-read.table(fileUrl, stringsAsFactors = FALSE)
data[,data$VAL]
data[data$VAL]
data[data$VAL,]
data[1]
data[1, 2]
data[1, 20]
data[20]
data[[20]]
install.packages("data.table")
library("data.table", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
millHomes <- subset(data, data$VAL==24)
View(millHomes)
millHomes <- subset(data, data$VAL==24,)
millHomes <- subset[data, data$VAL==24,]
millHomes <- subset(data, data$VAL==24,)
millHomes
millHomes <- subset(data, V1$VAL==24,)
millHomes <- subset(data, data$V1$VAL==24,)
millHomes <- subset(data, VAL==24,)
millHomes <- subset(data, $VAL==24,)
millHomes <- subset(data, V1$VAL==24,)
data
View(data)
data[1]
subset(data[,1])
?subset
subset(data, VAL==24)
subset(data, VAL==24, select= VAL)
data <-read.csv(fileUrl, stringsAsFactors = FALSE)
subset(data, VAL==24)
millHomes <- subset(data, VAL==24)
str(millHomes)
summary(millHomes)
library(xslx)
library(xlsx)
colIndex(7:15)
dat <- read.xlsx("https://d396qusza40orc.cloudfront.net/getdata%2Fdata2FDATA.gov_NGAP.xlsx", sheetIndex, colIndex=colIndex, rowIndex=rowIndex)
dat <- read.xlsx("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx", sheetIndex, colIndex=colIndex, rowIndex=rowIndex)
dat <- read.xlsx("http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx", sheetIndex, colIndex=colIndex, rowIndex=rowIndex)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx", destfile = "./dat/xlsx", method = "curl")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx", destfile = "./dat.xlsx", method = "curl")
dat <- read.xlsx("./dat.sxlsx", sheetIndex, colIndex=colIndex, rowIndex=rowIndex)
dat <- read.xlsx("./dat.xlsx", sheetIndex, colIndex=colIndex, rowIndex=rowIndex)
dat <- read.xlsx("./dat.xlsx", sheetIndex=1, colIndex=colIndex, rowIndex=rowIndex)
rowIndex <- 18:23
dat <- read.xlsx("./dat.xlsx", sheetIndex=1, colIndex=colIndex, rowIndex=rowIndex)
colIndex <- 7:15
dat <- read.xlsx("./dat.xlsx", sheetIndex=1, colIndex=colIndex, rowIndex=rowIndex)
sum(dat$Zip*dat$Ext, na.rm=T)
dat
install.packages("XML")
install.packages("XML2R")
library("XML", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
doc
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
xpathSApply(rootNode, "//zipcode", xmlValue)
?xpathSApply
?subset
str(zipcodes)
zipcodes
zipcodes <- xpathSApply(rootNode, "//zipcode", xmlValue)
str(zipcodes)
zip21231 <- zipcodes[zipcodes='21231']
length(zip21231)
zip21231
zip21231 <- zipcodes[zipcodes="21231"]
zip21231
zip21231 <- zipcodes[zipcodes=="21231"]
zip21231
length(zip21231)
?fread
library("data.table", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv", destfile = "./q5.csv", method = "curl")
?fread
DT <- fread("./q5.csv", ",")
DT
pwgtp15 <- tapply(DT$pwgtp15,DT$SEX,mean)
pwgtp15
pwgtp15 <- mean(DT$pwgtp15,by=DT$SEX)
pwgtp15
pwgtp15 <- DT[,mean(pwgtp15),by=SEX]
pwgtp15
pwgtp15 <- sapply(split(DT$pwgtp15,DT$SEX),mean)
pwgtp15
pwgtp15 <- rowMeans(DT)[DT$SEX==1];rowMeans(DT[DT$SEX==2]
pwgtp15 <- mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)
pwgtp15
pwgtp15 <- mean(DT$pwgtp15,by=DT$SEX)
pwgtp15
load("performance.R")
load("performance.R")
load("performance.R")
load("performance.R")
load("performance.R")
source("performance.R")
source("performance.R")
performa("mean(DT$pwgtp15,by=DT$SEX)")
source("performance.R")
performa("mean(DT$pwgtp15,by=DT$SEX)")
performa("tapply(DT$pwgtp15,DT$SEX,mean)")
performa("DT[,mean(pwgtp15),by=SEX]")
performa("sapply(split(DT$pwgtp15,DT$SEX),mean)")
system.time(mean(DT$pwgtp15,by=DT$SEX))
?system.time
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
pwgtp15 <- mean(DT$pwgtp15,by=DT$SEX)
pwgtp15
performa("mean(DT[DT$SEX==1,]$pwgtp15)")
performa("mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)")
performa("tapply(DT$pwgtp15,DT$SEX,mean)")
performa("sapply(split(DT$pwgtp15,DT$SEX),mean)")
performa("DT[,mean(pwgtp15),by=SEX]")
performa("mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15)")
performa("tapply(DT$pwgtp15,DT$SEX,mean)")
performa("DT[,mean(pwgtp15),by=SEX]")
performa("DT[,mean(pwgtp15),by=SEX]")
source("performance.R")
performa("sapply(split(DT$pwgtp15,DT$SEX),mean)")
source("performance.R")
performa("sapply(split(DT$pwgtp15,DT$SEX),mean)")
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
performa("tapply(DT$pwgtp15,DT$SEX,mean)")
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(mean(DT[DT$SEX==1,]$pwgtp15))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(mean(DT$pwgtp15,by=DT$SEX))
pwgtp15 <- mean(DT$pwgtp15,by=DT$SEX)
pwgtp15
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(DT[,mean(pwgtp15),by=SEX])
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, desfile= "./acs.csv", method="curl")
download.file(fileUrl, destfile= "./acs.csv", method="curl")
acs <- read.csv(("./acs.csv", colClasses ="character"))
acs <- read.csv("./acs.csv", colClasses ="character")
str(acs)
sqldf("select * from acs")
library("sqldf", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
sqldf("select * from acs")
sqldf("select pwgtp1 from acs where AGEP < 50")
sqldf("select pwgtp1, AGEP from acs where AGEP < 50")
sqldf("select distinct AGEP from acs")
sqldf("select distinct AGEP from acs order by AGEP")
uniqe(acs$AGEP)
unique(acs$AGEP)
con = url("http://biostat.jhsph.edu~jleek/contact.html")
htmlCode = readLines(con)
con = url("http://biostat.jhsph.edu/~jleek/contact.html")
htmlCode = readLines(con)
close(con)
htmlCode
?nchar
n10 <- nchar(htmlCode[10])
n10 <- nchar(htmlCode[10])
n10
n10 <- nchar(htmlCode[100])
n10
n10 <- nchar(htmlCode[10])
n20 <- nchar(htmlCode[20])
n30 <- nchar(htmlCode[30])
n100 <- nchar(htmlCode[100])
n10
n20
n30
n100
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile= "./acs_q4.csv", method="curl")
acs <- read.csv("./acs_q3.csv", colClasses ="character")
names(acs)
splitNames = strsplit(names(acs), "wgtp")
splitNames[123]
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile= "./gdp_q4.csv", method="curl")
gdp <- read.csv("./gdp_q3.csv", colClasses ="character")
gdp <- read.csv("./gdp_q4.csv", colClasses ="character")
str(gdp)
names(gdp)
gdp
gdp$X.3 <- sub(",", "", gdp$X.3)
head(gdp, 10)
gdp$X.3 <- gsub(",", "", gdp$X.3)
head(gdp, 10)
head(gdp)
gdp <- read.csv("./gdp_q4.csv", colClasses ="character")
head(gdp)
gdp$X.3 <- gsub(",", "", gdp$X.3)
average <- mean(as.numeric(gdp$X.3))
average
?mean
average <- mean(as.numeric(gdp$X.3), na.rm=TRUE)
average
gdp <- read.csv("./gdp_q4.csv", colClasses ="character")
gdp$X.3
head(gdp, 10)
gdp
gdp <- gdp[gdp$Gross.domestic.product.2012 X.1 > 0 & gdp$Gross.domestic.product.2012 X.1 < 191]
gdp <- gdp["gdp$Gross.domestic.product.2012 X.1" > 0 & "gdp$Gross.domestic.product.2012 X.1" < 191]
gdp$X.3 <- gsub(",", "", gdp$X.3)
average <- mean(as.numeric(gdp$X.3), na.rm=TRUE)
average
gdp
gdp <- read.csv("./gdp_q4.csv", colClasses ="character")
gdp[] <- gdp["gdp$Gross.domestic.product.2012 X.1" > 0 & "gdp$Gross.domestic.product.2012 X.1" < 191]
gdp
gdp[] <- gdp[as.numeric(gdp$Gross.domestic.product.2012 X.1) > 0 & as.numeric(gdp$Gross.domestic.product.2012 X.1) < 191]
gdp <- gdp[as.numeric(gdp$Gross.domestic.product.2012 X.1) > 0 & as.numeric(gdp$Gross.domestic.product.2012 X.1) < 191]
gdp <- gdp[(as.numeric(gdp$Gross.domestic.product.2012 X.1) > 0) & (as.numeric(gdp$Gross.domestic.product.2012 X.1) < 191)]
gdp
gdp <- read.csv("./gdp_q4.csv", colClasses ="character")
gdp
gdpf <- gdp[which(as.numeric(gdp$Gross.domestic.product.2012 X.1) > 0),]
gdpf <- gdp[which(as.numeric(gdp$Gross.domestic.product.2012) > 0),]
gdpf
gdfp$X.3 <- gsub(",", "", gdpf$X.3)
average <- mean(as.numeric(gdpf$X.3), na.rm=TRUE)
average
gdp <- read.csv("./gdp_q4.csv", colClasses ="character")
gdpf <- gdp[which(as.numeric(gdp$Gross.domestic.product.2012) > 0),]
gdfp$X.3 <- gsub(",", "", gdpf$X.3)
average <- mean(as.numeric(gdpf$X.3), na.rm=TRUE)
average
gdpf
gdp <- read.csv("./gdp_q4.csv", colClasses ="character")
gdpf <- gdp[which(as.numeric(gdp$Gross.domestic.product.2012) > 0),]
gdpf
gdpf$X.3 <- gsub(",", "", gdpf$X.3)
average <- mean(as.numeric(gdpf$X.3), na.rm=TRUE)
average
grep("^United", gdpf$X2)
grep("^United", gdpf$X.2)
head(edStats)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl, destfile= "./fedStats.csv", method="curl")
edStats <- read.csv("./fedStats.csv", colClasses ="character", stringsAsFactors = FALSE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile= "./gdp.csv", method="curl")
gdp <- read.csv("./gdp.csv", skip=5, colClasses="character", stringsAsFactors = FALSE, header=FALSE)
head(edStats)
head(edStats, 100)
mergedFile <- merge(gdpf, edStatsf, by.x="ccode", by.y="CountryCode", all=FALSE)
gdp <- read.csv("./gdp.csv", skip=5, colClasses="character", stringsAsFactors = FALSE, header=FALSE)
gdp <- gdp[,c(1:2, 4:5)]
gdpf <- gdp[which(as.numeric(gdp$rank) > 0),]
setnames(gdp, c("ccode", "rank", "cname", "gdp"))
mergedFile <- merge(gdpf, edStatsf, by.x="ccode", by.y="CountryCode", all=FALSE)
mergedFile <- merge(gdpf, edStats, by.x="ccode", by.y="CountryCode", all=FALSE)
setnames(gdpf, c("ccode", "rank", "cname", "gdp"))
mergedFile <- merge(gdpf, edStats, by.x="ccode", by.y="CountryCode", all=FALSE)
gdpf
setnames(gdpf, c("ccode", "rank", "cname", "gdp"))
setNames(gdpf, c("ccode", "rank", "cname", "gdp"))
mergedFile <- merge(gdpf, edStats, by.x="ccode", by.y="CountryCode", all=FALSE)
gdpf
gdp <- read.csv("./gdp.csv", skip=5, colClasses="character", stringsAsFactors = FALSE, header=FALSE)
gdp <- gdp[,c(1:2, 4:5)]
gdpf <- gdp[which(as.numeric(gdp$rank) > 0),]
setNames(gdpf, c("ccode", "rank", "cname", "gdp"))
gdp <- read.csv("./gdp.csv", skip=5, colClasses="character", stringsAsFactors = FALSE, header=FALSE)
gdp
gdp <- gdp[,c(1:2, 4:5)]
gdp
gdpf <- gdp[which(as.numeric(gdp$rank) > 0),]
gdpf
str(gdp$rank)
setNames(gdp, c("ccode", "rank", "cname", "gdp"))
gdpf <- gdp[which(as.numeric(gdp$rank) > 0),]
mergedFile <- merge(gdpf, edStats, by.x="ccode", by.y="CountryCode", all=FALSE)
gdp
gdp <- read.csv("./gdp.csv", skip=5, colClasses="character", stringsAsFactors = FALSE, header=FALSE)
gdp <- gdp[,c(1:2, 4:5)]
setNames(gdp, c("ccode", "rank", "cname", "gdp"))
gdpf <- gdp[which(as.numeric(gdp$rank) > 0),]
gdpf
str(gdp$rank)
gdp
gdp <- read.csv("./gdp.csv", skip=5, colClasses="character", stringsAsFactors = FALSE, header=FALSE)
gdp <- gdp[,c(1:2, 4:5)]
gdp
setNames(gdp, c("ccode", "rank", "cname", "gdp"))
str(gdp$rank)
gdp
setNames(gdp, c("ccode", "rank", "cname", "gdp"))
str(gdp)
gdp <-setNames(gdp, c("ccode", "rank", "cname", "gdp"))
gdpf <- gdp[which(as.numeric(gdp$rank) > 0),]
mergedFile <- merge(gdpf, edStats, by.x="ccode", by.y="CountryCode", all=FALSE)
mergeFile
mergedFile
gout <- grep("Fiscal year end: June", gdpf$Special.Notes)
gout
gout <- grep("Fiscal year end", gdpf$Special.Notes, value=TRUE)
gout
gdpf$Special.Notes
gpdf
gdpf
gout <- grep("Fiscal year end", mergedFile$Special.Notes, value=TRUE)
gout
gout <- grep("Fiscal year end: June", mergedFile$Special.Notes, value=TRUE)
gout
gout <- grep("Fiscal year end: June", edStats$Special.Notes, value=TRUE)
gout
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN", auto.assign=FALSE)
sampleTimes = index(amzn)
sampleTimes
install.packages("lubridate")
library("lubridate", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
sampleTimes2 <- grep("^2012", samplesTimes)
sampleTimes2 <- grep("^2012", sampleTimes)
sampleTimes2
str(sampleTimes2)
sampleTimes2 <- grep("^2012", sampleTimes, value=TRUE)
sampleTimes2
sampleTimes3 <- format(sampleTimes2, %A)
sampleTimes3 <- format(as.date(sampleTimes2), %A)
?as.date
sampleTimes3 <- format(as.date(sampleTimes2, %A))
sampleTimes3 <- as.date(sampleTimes2, %a %b %d)
sampleTimes3 <- as.date(sampleTimes2, "%a %b %d")
sampleTimes3 <- format(sampleTimes2, "%a %b %d")
?date
sampleTimes3 <- as.Date(sampleTimes2, "%a %b %d")
sampleTimes3
sampleTimes2
sampleTimes3 <- as.Date(sampleTimes2[1], "%a %b %d")
sampleTimes3
sampleTimes3 <- as.Date(sampleTimes2[1], "%Y-%m-%d")
sampleTimes3
str(sampleTimes3)
sampleTimes3 <- as.Date(sampleTimes2, "%Y-%m-%d")
sampleTimes3
sampleTimes4 <- format(sampleTimes3, "%a %b %Y")
sampleTimes4
sampleTimes5 <- grep("^Mon")
sampleTimes5 <- grep("^Mon", sampleTimes4)
sampleTimes5
str(sampleTimes5)
?dev.copy2pdf
setwd("~/ExploratoryDataAnalysis/Project1")
data <- read.csv("./household_power_consumption.txt", sep = ";",colClasses ="character")
closeAllConnections()
data <- subset(data, Date == "2/2/2007" | Date == "1/2/2007")
hist(as.numeric(data2$Global_active_power), xlab="Global Active Power (kilowatts)", main="Global Active Power", col="red")
png(filename="plot1.png", width=480, height=480, units= "px")
dev.off()
source(plot1.R)
setwd("~/ExData_Plotting1")
source(plot1.R)
ls
plot1.R
wkdir
wkdir()
setwd("~/ExData_Plotting1")
source(plot1.R)
run(plot1.R)
?run
source("plot1.R")
source("plot1.R")
source("plot1.R")
source("plot1.R")
dev(cur)
dev.cur()
?dev
?dev.cur()
source("plot1.R")
source("plot2.R")
source("plot2.R")
source("plot2.R")
source("plot2.R")
source("plot3.R")
source("plot3.R")
?setnames
library("data.table", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
source("plot3.R")
source("plot1.R")
source("plot4.R")
source("plot4.R")
source("plot4.R")
source("plot4.R")
source("plot3.R")
source("plot4.R")
temp <- tempfile()
download.file("https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip",temp)
setwd("~/ExploratoryDataAnalysis/Project1")
url1<- "https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip"
download.file(url1,"./hpc.zip")
library("RCurl", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
download.file(url1,"./hpc.zip")
myzip = "exdata_data_household_power_consumption.zip"
download.file("https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold%2Fpower%2Fconsumption.zip", destfile=myzip,method="curl")
unzip(myzip)
download.file("https://d396qusza40orc.cloudfront.net/exdata%2Fdata%2Fhousehold_power_consumption.zip", destfile=myzip,method="curl")
unzip(myzip)
source("plot1.R")
setwd("~/ExData_Plotting1")
source("plot1.R")
?fread
?download.file
?rbind
source("plot1.R")
source("plot2.R")
source("plot3.R")
source("plot4.R")
